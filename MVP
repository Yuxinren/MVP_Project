# import sounddevice as sd
# import numpy as np
# import queue
# import threading
# import whisper
# import your_zephyr_module  # Replace with actual Zephyr module
# import pyttsx3
# # Global variables
# running = True
# audio_queue = queue.Queue()

# # Initialize Whisper model
# whisper_model = whisper.load_model("tiny")  # Choose the appropriate model size

# # Initialize Text-to-Speech engine
# tts_engine = pyttsx3.init()

# def wake_word_detected(audio_data):
#     """
#     Analyze the audio data to detect the wake word.
#     Return True if the wake word is detected, False otherwise.
#     """
#     # Implement wake word detection logic
#     return False

# def audio_callback(indata, frames, time, status):
#     """
#     This is called for each audio buffer from the microphone.
#     """
#     if status:
#         print(status, file=sys.stderr)
#     audio_queue.put(indata.copy())

# def listen_for_wake_word():
#     """
#     Listen to the microphone and check for the wake word.
#     """
#     global running
#     with sd.InputStream(callback=audio_callback):
#         while running:
#             audio_data = audio_queue.get()
#             if wake_word_detected(audio_data):
#                 process_command()

# def process_command():
#     """
#     Capture audio for the command, run it through Whisper, and pass it to Zephyr.
#     """
#     command_audio = capture_command_audio()  # Implement this function
#     transcription = whisper_model.transcribe(command_audio)
#     response = your_zephyr_module.generate_response(transcription)
#     speak_response(response)

# def capture_command_audio():
#     """
#     Capture the command audio. Implement logic to capture audio until a pause is detected.
#     """
#     # Implement audio capture with pause detection
#     return b''  # Return the captured audio bytes

# def speak_response(response_text):
#     """
#     Use the TTS engine to speak out the response.
#     """
#     tts_engine.say(response_text)
#     tts_engine.runAndWait()

# def main():
#     listen_thread = threading.Thread(target=listen_for_wake_word)
#     listen_thread.start()

# if __name__ == "__main__":
#     main()


# import torch
# from transformers import pipeline

# pipe = pipeline("text-generation", model="HuggingFaceH4/zephyr-7b-beta", torch_dtype=torch.bfloat16, device_map="auto")

# messages = [
#     {
#         "role": "system",
#         "content": "You are a friendly chatbot who always responds in the style of a pirate",
#     },
#     {"role": "user", "content": "How many helicopters can a human eat in one sitting?"},
# ]
# prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
# outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
# print(outputs[0]["generated_text"])

# import torch
# from transformers import pipeline
# model_name = "HuggingFaceH4/zephyr-7b-beta"

# pipe = pipeline(
#     "text-generation",
#     model=model_name,
#     torch_dtype=torch.bfloat16,
#     device_map="auto",
# )

# prompt = "Write a Python function that can clean the HTML tags from the file:"

# outputs = pipe(
#     prompt,
#     max_new_tokens=300,
#     do_sample=True,
#     temperature=0.7,
#     top_k=50,
#     top_p=0.95,
# )
# print(outputs[0]["generated_text"])


# import ollama

# stream = ollama.chat(
#     model='stablelm-zephyr',
#     messages=[
#         {'role': 'user', 
#          'content': 'Act as a smart speaker algorithm to decide which function to call. The speaker received the following user request: "What\\\'s the weather like today in Miami" You need to choose the most appropriate command from the list below to accurately respond to the user\\\'s needs.'},
#         {'role': 'user',
#          'content': 'Now, the user asks: "Set an alarm for 7 AM tomorrow." Choose the appropriate command.'},
#         {'role': 'user',
#          'content': 'Finally, the user requests: "Play some relaxing music." Select the relevant command from your options.'}
#     ],
#     stream=True,
# )

# for chunk in stream:
#     print(chunk['message']['content'], end='', flush=True)


# import ollama

# def format_user_input(input_text):
#     commands = ("Play Music, Set Alarm, Check Weather, Set Timer, Read News, Control Smart Home Devices, "
#                 "Send a Message, Create Calendar Events, Play Audiobooks or Podcasts, Ask for Definitions or Facts, "
#                 "Shopping List Additions, Play Radio, Call Uber, Set Reminders, Cooking Assistance, Translation Services, "
#                 "Flight Information, Stock Market Updates, Find Phone, Bedtime Routine")
#     return (f'Act as a smart speaker algorithm to decide which function to call. The speaker received the following user request: "{input_text}" '
#             f'You need to choose the most appropriate command from the list below to accurately respond to the user\'s needs. '
#             f'Do not answer the question, just pick a function to call. Considering the context and the user\'s intent, '
#             f'which command should execute to best fulfill the user\'s request? Select from the options below. Reply with just the command name from the above list and nothing else. '
#             f'The available commands are: {commands}')

# def process_user_input_and_respond():
#     while True:
#         user_input = input("Enter your request (or type 'exit' to stop): ")
#         if user_input.lower() == 'exit':
#             break
#         formatted_input = format_user_input(user_input)
        
#         # Assuming ollama.chat is the correct method based on your initial example
#         stream = ollama.chat(
#             model='stablelm-zephyr',
#             messages=[{'role': 'user', 'content': formatted_input}],
#             stream=True,
#         )

#         # Assuming the response is directly iterable and provides the desired output
#         for chunk in stream:
#             print(chunk['message']['content'], end='', flush=True)


# import whisper
# import pyaudio
# import wave
# import io
# import contextlib
# from gtts import gTTS
# import playsound
# import os

# # Initialize Whisper model
# model = whisper.load_model("base")

# # Initialize PyAudio
# p = pyaudio.PyAudio()

# # Stream settings
# FORMAT = pyaudio.paInt16
# CHANNELS = 1
# RATE = 16000
# CHUNK = 1024
# RECORD_SECONDS = 5

# # Record audio for a fixed duration
# def record_audio(duration=RECORD_SECONDS):
#     stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
#     print("* recording")
#     frames = []

#     for _ in range(0, int(RATE / CHUNK * duration)):
#         data = stream.read(CHUNK)
#         frames.append(data)

#     print("* done recording")
#     stream.stop_stream()
#     stream.close()

#     # Save the recorded data as a WAV file
#     wf = wave.open("output.wav", 'wb')
#     wf.setnchannels(CHANNELS)
#     wf.setsampwidth(p.get_sample_size(FORMAT))
#     wf.setframerate(RATE)
#     wf.writeframes(b''.join(frames))
#     wf.close()

#     return "output.wav"

# # Convert speech to text using Whisper
# def speech_to_text(audio_file):
#     result = model.transcribe(audio_file)
#     command = result["text"]
#     print(f"Command: {command}")
#     return command

# # Simulate Zephyr command processing
# def process_command(command):
#     # This is a placeholder for actual command processing
#     return f"Processed command: {command}"

# # Speak text using Google TTS
# def speak_text(text):
#     tts = gTTS(text=text, lang='en')
#     tts.save("response.mp3")
#     playsound.playsound("response.mp3")
#     os.remove("response.mp3")

# def main():
#     while True:
#         print("Say 'Hello' to activate...")
#         # Wait for the wake word
#         record_audio(3)  # Record a short clip to check for the wake word
#         command = speech_to_text("output.wav")
#         if "hello" in command.lower():
#             audio_file = record_audio()
#             command = speech_to_text(audio_file)
#             response = process_command(command)
#             speak_text(response)
#         else:
#             print("Wake word not detected.")

# if __name__ == "__main__":
#     main()





import pyaudio
import wave
import whisper
import ollama
from gtts import gTTS
import playsound
import os

# Initialize Whisper model
model = whisper.load_model("base")

# Initialize PyAudio
p = pyaudio.PyAudio()

# Stream settings
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024
RECORD_SECONDS = 5
WAKE_WORD = "hello"

def record_audio():
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
    frames = []

    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):
        data = stream.read(CHUNK)
        frames.append(data)

    stream.stop_stream()
    stream.close()

    wf = wave.open("output.wav", 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

    return "output.wav"

def speech_to_text(audio_file):
    result = model.transcribe(audio_file)
    command = result["text"]
    return command

def format_user_input(input_text):
    commands = ("Play Music, Set Alarm, Check Weather, Set Timer, Read News, Control Smart Home Devices, "
                "Send a Message, Create Calendar Events, Play Audiobooks or Podcasts, Ask for Definitions or Facts, "
                "Shopping List Additions, Play Radio, Call Uber, Set Reminders, Cooking Assistance, Translation Services, "
                "Flight Information, Stock Market Updates, Find Phone, Bedtime Routine")
    return (f'Act as a smart speaker algorithm to decide which function to call. The speaker received the following user request: "{input_text}" '
            f'You need to choose the most appropriate command from the list below to accurately respond to the user\'s needs. '
            f'Do not answer the question, just pick a function to call. Considering the context and the user\'s intent, '
            f'which command should execute to best fulfill the user\'s request? Select from the options below. Reply with just the command name from the above list and nothing else. '
            f'The available commands are: {commands}')

def process_with_ollama(user_input):
    formatted_input = format_user_input(user_input)
    
    stream = ollama.chat(
        model='stablelm-zephyr',
        messages=[{'role': 'user', 'content': formatted_input}],
        stream=True,
    )

    response_content = ""
    for chunk in stream:
        response_content += chunk['message']['content']

    return response_content
def speak_text(text):
    tts = gTTS(text=text, lang='en')
    tts_file = "tts_output.mp3"
    tts.save(tts_file)
    playsound.playsound(tts_file)
    os.remove(tts_file)

def is_wake_word_present(command, wake_word=WAKE_WORD):
    return wake_word in command.lower()

def main():
    print("Say 'Hello' to start the session.")
    while True:
        audio_file = record_audio()
        command = speech_to_text(audio_file)

        if is_wake_word_present(command):
            print("Session activated. Start speaking your commands.")
            while True:
                audio_file = record_audio()
                command = speech_to_text(audio_file)

                if command.lower() == 'exit':
                    print("Exiting session.")
                    break

                print(f"User Input: {command}")
                zephyr_command = process_with_ollama(command)
                print(f"Zephyr Command: {zephyr_command}")
                speak_text(zephyr_command)

if __name__ == "__main__":
    main()

